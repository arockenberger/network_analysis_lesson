{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis with Python and the NetworkX package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import csv\n",
    "from operator import itemgetter\n",
    "import community\n",
    "# import the packages we need for doing network analysis and for working with structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quakers_nodelist.csv', 'r') as nodecsv:\n",
    "    nodereader = csv.reader(nodecsv)\n",
    "    nodes = [n for n in nodereader][1:]\n",
    "# read in the csv-file quakers_nodelist and store the information in a variable called nodereader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = [n[0] for n in nodes]\n",
    "# get a list of just the node names (the first item in each row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quakers_edgelist.csv', 'r') as edgecsv:\n",
    "    edgereader = csv.reader(edgecsv)\n",
    "    edges = [tuple(e) for e in edgereader][1:]\n",
    "# Read in the edgelist file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "print(len(node_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n"
     ]
    }
   ],
   "source": [
    "print(len(edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "# Initialize the graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(node_names)\n",
    "# Add nodes to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from(edges)\n",
    "# Add edges to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 119\n",
      "Number of edges: 174\n",
      "Average degree:   2.9244\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "# Print information about the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sig_dict = {}\n",
    "gender_dict = {}\n",
    "birth_dict = {}\n",
    "death_dict = {}\n",
    "id_dict = {}\n",
    "# Create dictionaries for each column in the nodes list; they are empty {} \n",
    "# and will be filled later with contents from the quaker_nodes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    hist_sig_dict[node[0]] = node[1]\n",
    "    gender_dict[node[0]] = node[2]\n",
    "    birth_dict[node[0]] = node[3]\n",
    "    death_dict[node[0]] = node[4]\n",
    "    id_dict[node[0]] = node[5]\n",
    "# Loop through the list, one row at a time\n",
    "# We create 'pairs' where we assign the attributes on indexes[1,2,3,4,5] to the node on index[0]\n",
    "# Think about it like this:\n",
    "# In row 1, the first name is 'Josep Wyeth'\n",
    "# Joseph has a couple of attributes that describe him in a way that is useful for our research\n",
    "# For example, Joseph was a religious writer, an attribute from the column 'Historical Significance'.\n",
    "# Think about the column as a dictionary in Python terminology (stuff that is between {})\n",
    "# Joseph is a man, another attribute, this time from the 3rd row (in Python counting, index[2];\n",
    "# the information is stored in our dictionary called 'gender_dict'\n",
    "# And so on\n",
    "# For every one of Joseph's attributes we have to tell NetworkX to pair it with the node Joseph\n",
    "# A node can have any number of attributes (as far as I know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, hist_sig_dict, 'historical_significance')\n",
    "nx.set_node_attributes(G, gender_dict, 'gender')\n",
    "nx.set_node_attributes(G, birth_dict, 'birthyear')\n",
    "nx.set_node_attributes(G, death_dict, 'deathyear')\n",
    "nx.set_node_attributes(G, id_dict, 'id')\n",
    "# Add attributes to the graph G; set_node_attribute takes three variables:\n",
    "# 1) the graph G to which you are adding the attribute\n",
    "# 2) the dictionary of id-attribute pairs\n",
    "# 3) the name of the new attribute\n",
    "# The result is that all nodes now have the six attributes and we can access this information any time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph Wyeth male\n",
      "Alexander Skene of Newtyle male\n",
      "James Logan male\n",
      "Dorcas Erbery female\n",
      "Lilias Skene male\n",
      "William Mucklow male\n",
      "Thomas Salthouse male\n",
      "William Dewsbury male\n",
      "John Audland male\n",
      "Richard Claridge male\n",
      "William Bradford male\n",
      "Fettiplace Bellers male\n",
      "John Bellers male\n",
      "Isabel Yeamans female\n",
      "George Fox the younger male\n",
      "George Fox male\n",
      "John Stubbs male\n",
      "Anne Camm female\n",
      "John Camm male\n",
      "Thomas Camm male\n",
      "Katharine Evans female\n",
      "Lydia Lancaster female\n",
      "Samuel Clarridge male\n",
      "Thomas Lower male\n",
      "Gervase Benson male\n",
      "Stephen Crisp male\n",
      "James Claypoole male\n",
      "Thomas Holme male\n",
      "John Freame male\n",
      "John Swinton male\n",
      "William Mead male\n",
      "Henry Pickworth male\n",
      "John Crook male\n",
      "Gilbert Latey male\n",
      "Ellis Hookes male\n",
      "Joseph Besse male\n",
      "James Nayler male\n",
      "Elizabeth Hooten female\n",
      "George Whitehead male\n",
      "John Whitehead male\n",
      "William Crouch male\n",
      "Benjamin Furly male\n",
      "Silvanus Bevan male\n",
      "Robert Rich male\n",
      "John Whiting male\n",
      "Christopher Taylor male\n",
      "Thomas Lawson male\n",
      "Richard Farnworth male\n",
      "William Coddington male\n",
      "Thomas Taylor male\n",
      "Richard Vickris male\n",
      "Robert Barclay male\n",
      "Jane Sowle female\n",
      "Tace Sowle male\n",
      "Leonard Fell male\n",
      "Margaret Fell female\n",
      "George Bishop male\n",
      "Elizabeth Leavens female\n",
      "Thomas Curtis male\n",
      "Alice Curwen female\n",
      "Alexander Parker male\n",
      "John Wilkinson male\n",
      "Thomas Aldam male\n",
      "David Barclay of Ury male\n",
      "David Barclay male\n",
      "Sir Charles Wager male\n",
      "George Keith male\n",
      "James Parnel male\n",
      "Peter Collinson male\n",
      "Franciscus Mercurius van Helmont male\n",
      "William Caton male\n",
      "Francis Howgill male\n",
      "Richard Hubberthorne male\n",
      "William Ames male\n",
      "William Rogers male\n",
      "Isaac Norris male\n",
      "Anthony Sharp male\n",
      "Mary Fisher female\n",
      "Anne Conway Viscountess Conway and Killultagh female\n",
      "Samuel Fisher male\n",
      "Francis Bugg male\n",
      "Sarah Gibbons female\n",
      "William Tomlinson male\n",
      "Humphrey Norton male\n",
      "William Gibson male\n",
      "Gideon Wanton male\n",
      "John Wanton male\n",
      "Grace Chamber female\n",
      "Mary Prince female\n",
      "John Bartram male\n",
      "Edward Haistwell male\n",
      "John ap John male\n",
      "John Rous male\n",
      "Anthony Pearson male\n",
      "Solomon Eccles male\n",
      "John Burnyeat male\n",
      "Edward Burrough male\n",
      "Rebecca Travers female\n",
      "William Edmundson male\n",
      "Sarah Cheevers female\n",
      "Edward Pyott male\n",
      "Daniel Quare male\n",
      "John Penington male\n",
      "Mary Penington female\n",
      "Charles Marshall male\n",
      "Humphrey Woolrich male\n",
      "William Penn male\n",
      "Mary Pennyman female\n",
      "Dorothy Waugh female\n",
      "David Lloyd male\n",
      "Lewis Morris male\n",
      "Martha Simmonds female\n",
      "John Story male\n",
      "Thomas Story male\n",
      "Thomas Ellwood male\n",
      "William Simpson male\n",
      "Samuel Bownas male\n",
      "John Perrot male\n",
      "Hannah Stranger female\n"
     ]
    }
   ],
   "source": [
    "# Example: Print out all birth years of the nodes\n",
    "for n in G.nodes():\n",
    "    print(n, G.node[n]['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do that for the other attributes, too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you have learned how to create a Graph object and how to add attributes to it.\n",
    "# In the next section we will learn a variety of metrics available in NetworkX and how to access them.\n",
    "# That was the most complex and dense code you will write in this workshop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Density\n",
    "# The ratio of actual edges in the network to all possible edges in the network; in an undirected network,\n",
    "# there could be a single edge between any two nodes, but as you can see in the visualisation, only a few\n",
    "# of those possible edges are actually present.\n",
    "# Network density gives you a quick sense of how closely knit your network is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network density: 0.02478279447372169\n"
     ]
    }
   ],
   "source": [
    "density = nx.density(G)\n",
    "print(\"Network density:\", density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest path between Fell and Whitehead: ['Margaret Fell', 'George Fox', 'George Whitehead']\n"
     ]
    }
   ],
   "source": [
    "# Finding the shortest path between two nodes\n",
    "# Margaret Fell and George Whitehead\n",
    "fell_whitehead_path = nx.shortest_path(G, source='Margaret Fell', target='George Whitehead')\n",
    "print('Shortest path between Fell and Whitehead:', fell_whitehead_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function shows us the shortest path between Fell and Whitehead is one George Fox;\n",
    "# Fell and Whitehead are not directly connected, but indirectly via a mutual contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of that path: 2\n"
     ]
    }
   ],
   "source": [
    "print('Length of that path:', len(fell_whitehead_path)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diameter\n",
    "# Is the longest of all short paths; this measure is designed to give you a sense of the network's overall size,\n",
    "# the distance from one end of the network to another\n",
    "# Using the function nx.diameter(G) will result in an error that tells us that it is not possible calculate the\n",
    "# diameter because the graph is not connected. Which means, that there are nodes in our graph that are only \n",
    "# connected to each other, but not to any other nodes.\n",
    "# So, lets check for that first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(nx.is_connected(G))\n",
    "# Returs False if the graph is not connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network diameter of largest component: 8\n"
     ]
    }
   ],
   "source": [
    "components = nx.connected_components(G)\n",
    "largest_component = max(components, key=len)\n",
    "# Using nx.connected_components to get the list of components,\n",
    "# then using the max(f) function to find the largest one\n",
    "# From this we create a subgraph of just the largest component,\n",
    "# then calculate the diameter of this subgraph, like with density:\n",
    "subgraph = G.subgraph(largest_component)\n",
    "diameter = nx.diameter(subgraph)\n",
    "print('Network diameter of largest component:', diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triadic closure: 0.16937799043062202\n"
     ]
    }
   ],
   "source": [
    "# Triadic closure\n",
    "triadic_closure = nx.transitivity(G)\n",
    "print('Triadic closure:', triadic_closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'historical_significance': 'Quaker leader and founder of Pennsylvania', 'gender': 'male', 'birthyear': '1644', 'deathyear': '1718', 'id': '10009531', 'degree': 18}\n"
     ]
    }
   ],
   "source": [
    "degree_dict = dict(G.degree(G.nodes()))\n",
    "nx.set_node_attributes(G, degree_dict, 'degree')\n",
    "print(G.node['William Penn'])\n",
    "# This function adds degree, which is has calculated from the graph, as an attribute to the nodes.\n",
    "# In one go we create a now dictionary (think of it as another column) called degree where we store\n",
    "# the results of this calculation for each node\n",
    "# With the print command we can check if we were successful adding the degree-attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by degree:\n",
      "('George Fox', 22)\n",
      "('William Penn', 18)\n",
      "('James Nayler', 16)\n",
      "('George Whitehead', 13)\n",
      "('Margaret Fell', 13)\n",
      "('Benjamin Furly', 10)\n",
      "('Edward Burrough', 9)\n",
      "('George Keith', 8)\n",
      "('Thomas Ellwood', 8)\n",
      "('Francis Howgill', 7)\n",
      "('John Perrot', 7)\n",
      "('John Audland', 6)\n",
      "('Richard Farnworth', 6)\n",
      "('Alexander Parker', 6)\n",
      "('John Story', 6)\n",
      "('John Stubbs', 5)\n",
      "('Thomas Curtis', 5)\n",
      "('John Wilkinson', 5)\n",
      "('William Caton', 5)\n",
      "('Anthony Pearson', 5)\n"
     ]
    }
   ],
   "source": [
    "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)\n",
    "print('Top 20 nodes by degree:')\n",
    "for d in sorted_degree[:20]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest 15 nodes by degree:\n",
      "('Gideon Wanton', 1)\n",
      "('John Wanton', 1)\n",
      "('Grace Chamber', 1)\n",
      "('Edward Haistwell', 1)\n",
      "('John ap John', 1)\n",
      "('John Rous', 1)\n",
      "('Sarah Cheevers', 1)\n",
      "('John Penington', 1)\n",
      "('Humphrey Woolrich', 1)\n",
      "('Mary Pennyman', 1)\n",
      "('Dorothy Waugh', 1)\n",
      "('Lewis Morris', 1)\n",
      "('Thomas Story', 1)\n",
      "('William Simpson', 1)\n",
      "('Samuel Bownas', 1)\n"
     ]
    }
   ],
   "source": [
    "# Lets try this for a couple of other sortings\n",
    "# For example we can change the Top 20 to a Top 5 or a Top 30\n",
    "# Keep in mind that lists with more than 20 items are hard to 'quickly get' for humans\n",
    "# We can also sort from the lowest degree to the hightest\n",
    "sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)\n",
    "print('Lowest 15 nodes by degree:')\n",
    "for d in sorted_degree[104:]:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two more centrality measures, betweenness and eigenvector\n",
    "betweenness_dict = nx.betweenness_centrality(G)\n",
    "eigenvector_dict = nx.eigenvector_centrality(G)\n",
    "# Now we assign each as an attribute to the nodes in our network:\n",
    "nx.set_node_attributes(G, betweenness_dict, 'betweenness')\n",
    "nx.set_node_attributes(G, eigenvector_dict, 'eigenvector')\n",
    "# Now lets sort our nodes by these attributes as we have done before, only showing the Top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by betweenness factor:\n",
      "('William Penn', 0.23999456006192205)\n",
      "('George Fox', 0.23683257726065216)\n",
      "('George Whitehead', 0.12632024847366005)\n",
      "('Margaret Fell', 0.12106792237170329)\n",
      "('James Nayler', 0.10446026280446098)\n",
      "('Benjamin Furly', 0.06419626175167242)\n",
      "('Thomas Ellwood', 0.046190623885104545)\n",
      "('George Keith', 0.045006564009171565)\n",
      "('John Audland', 0.04164936340077581)\n",
      "('Alexander Parker', 0.03893676140525336)\n",
      "('John Story', 0.028990098622866983)\n",
      "('John Burnyeat', 0.028974117533439564)\n",
      "('John Perrot', 0.02829566854990583)\n",
      "('James Logan', 0.026944806605823553)\n",
      "('Richard Claridge', 0.026944806605823553)\n",
      "('Robert Barclay', 0.026944806605823553)\n",
      "('Elizabeth Leavens', 0.026944806605823553)\n",
      "('Thomas Curtis', 0.026729751729751724)\n",
      "('John Stubbs', 0.024316593960227152)\n",
      "('Mary Penington', 0.02420824624214454)\n"
     ]
    }
   ],
   "source": [
    "sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)\n",
    "print('Top 20 nodes by betweenness factor:')\n",
    "for b in sorted_betweenness[:20]:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 nodes by eigenvector:\n",
      "('George Fox', 0.4491750710859924)\n",
      "('James Nayler', 0.3352974100447867)\n",
      "('William Penn', 0.2703220115399868)\n",
      "('Margaret Fell', 0.253170949905681)\n",
      "('George Whitehead', 0.2497455334914196)\n",
      "('Edward Burrough', 0.23147427604862297)\n",
      "('Francis Howgill', 0.1909539378268105)\n",
      "('Benjamin Furly', 0.1878520634691651)\n",
      "('John Perrot', 0.1849692807795611)\n",
      "('George Keith', 0.18384690867915351)\n",
      "('Thomas Ellwood', 0.17608142535843857)\n",
      "('Richard Farnworth', 0.15368535029296415)\n",
      "('John Crook', 0.1327158126880779)\n",
      "('Rebecca Travers', 0.1184804064465093)\n",
      "('Alexander Parker', 0.11587808682088324)\n",
      "('Anthony Pearson', 0.11120476725256784)\n",
      "('William Dewsbury', 0.11057869321157121)\n",
      "('John Stubbs', 0.10693500692141825)\n",
      "('John Audland', 0.0983088971933375)\n",
      "('Thomas Salthouse', 0.09548628544138771)\n"
     ]
    }
   ],
   "source": [
    "sorted_eigenvector = sorted(eigenvector_dict.items(), key=itemgetter(1), reverse=True)\n",
    "print('Top 20 nodes by eigenvector:')\n",
    "for e in sorted_eigenvector[:20]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: William Penn | Betweenness Centrality: 0.23999456006192205 | Degree: 18\n",
      "Name: George Fox | Betweenness Centrality: 0.23683257726065216 | Degree: 22\n",
      "Name: George Whitehead | Betweenness Centrality: 0.12632024847366005 | Degree: 13\n",
      "Name: Margaret Fell | Betweenness Centrality: 0.12106792237170329 | Degree: 13\n",
      "Name: James Nayler | Betweenness Centrality: 0.10446026280446098 | Degree: 16\n",
      "Name: Benjamin Furly | Betweenness Centrality: 0.06419626175167242 | Degree: 10\n",
      "Name: Thomas Ellwood | Betweenness Centrality: 0.046190623885104545 | Degree: 8\n",
      "Name: George Keith | Betweenness Centrality: 0.045006564009171565 | Degree: 8\n",
      "Name: John Audland | Betweenness Centrality: 0.04164936340077581 | Degree: 6\n",
      "Name: Alexander Parker | Betweenness Centrality: 0.03893676140525336 | Degree: 6\n",
      "Name: John Story | Betweenness Centrality: 0.028990098622866983 | Degree: 6\n",
      "Name: John Burnyeat | Betweenness Centrality: 0.028974117533439564 | Degree: 4\n",
      "Name: John Perrot | Betweenness Centrality: 0.02829566854990583 | Degree: 7\n",
      "Name: James Logan | Betweenness Centrality: 0.026944806605823553 | Degree: 4\n",
      "Name: Richard Claridge | Betweenness Centrality: 0.026944806605823553 | Degree: 2\n",
      "Name: Robert Barclay | Betweenness Centrality: 0.026944806605823553 | Degree: 3\n",
      "Name: Elizabeth Leavens | Betweenness Centrality: 0.026944806605823553 | Degree: 2\n",
      "Name: Thomas Curtis | Betweenness Centrality: 0.026729751729751724 | Degree: 5\n",
      "Name: John Stubbs | Betweenness Centrality: 0.024316593960227152 | Degree: 5\n",
      "Name: Mary Penington | Betweenness Centrality: 0.02420824624214454 | Degree: 4\n"
     ]
    }
   ],
   "source": [
    "# Detecting interesting stuff in our network but finding out what's unusual or unexpected\n",
    "# We can do this by comparing degree and betweenness\n",
    "# Lets look at Elizabeth Leavens, who has a high betweenness factor, but doesn't show up in the high degree list\n",
    "# For this, we get first the Top 20 betweenness nodes as a list\n",
    "top_betweenness = sorted_betweenness[:20]\n",
    "# Then we find and print their degree:\n",
    "for tb in top_betweenness:\n",
    "    degree = degree_dict[tb[0]]\n",
    "    print('Name:', tb[0], '| Betweenness Centrality:', tb[1], '| Degree:', degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection with Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commonly, what we want to know about networks is if there are subgroups or communities within the larger social structure\n",
    "# Is it a network where everyone knows everyone? Or is several subgroups that are only connected by a few, or just one,\n",
    "# person?\n",
    "# There are many ways to calculate communities, but most commonly used is Modularity.\n",
    "# Modularity is a measure of relative density in the network; A community, or 'module' has high density relative\n",
    "# to other nodes within its community or module but low density with those outside. Modularity gives an overall\n",
    "# score of how fractious a network is. That score can be used to partition the network and return the individual communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community detection with NetworkX requires a little more setup than other metrics\n",
    "# Modularity is not included in the NetworkX package, but there is an additional package for this, the \n",
    "# python-louvain packgage we downloaded in the beginning\n",
    "# For community detection we only want one function from it, best_partition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import community\n",
    "# communities = community.best_partition(G)\n",
    "\n",
    "# OBS! This produces an AttributeError, see Issue#3 here https://github.com/taynaud/python-louvain/issues/3\n",
    "# Following the suggestions, I have not succeeded in getting it running yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.set_node_attributes(G, communities, 'modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
